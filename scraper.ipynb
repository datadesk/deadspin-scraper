{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deadspin scraper\n",
    "\n",
    "By [Ben Welsh](https://palewi.re/who-is-ben-welsh/)\n",
    "\n",
    "This notebook scrapes metadata tracking pageviews of posts on Deadspin. Its results were used by Kim Janssen to write the Los Angeles Times story [\"I checked the math of the media bosses who told Deadspin to ‘stick to sports.’ It doesn’t add up.\"](https://www.latimes.com/entertainment-arts/business/story/2019-11-01/deadspin-stick-to-sports-bad-math)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FwOw9UPYsQcD",
    "outputId": "1df6bc1b-a5ca-4884-db5c-0948f9aa7552"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk back from the Deadspin homepage through its archives, downloading every link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NB0OKegfsihD"
   },
   "outputs": [],
   "source": [
    "link_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-ALtHZ2tTUE"
   },
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    # Get the page's HTML\n",
    "    print(f\"Requesting {url}\")\n",
    "    r = requests.get(url)\n",
    "    html = r.content\n",
    "    \n",
    "    # Scrape out all the links\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    \n",
    "    # Add them to our master list\n",
    "    print(f\"Logging {len(links)} links\")\n",
    "    link_list.extend([l['href'] for l in links if l.get(\"href\", None)])\n",
    "    \n",
    "    # Grab the next page link and get recursive\n",
    "    next_url = links[-1]['href']\n",
    "    get_links(f\"https://www.deadspin.com/{next_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "llZjC9n4skUa",
    "outputId": "d6df892b-67c7-41b8-b555-c889de0d20b6"
   },
   "outputs": [],
   "source": [
    "get_links(\"https://www.deadspin.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dedepulicate the link list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUlPS46esrVA"
   },
   "outputs": [],
   "source": [
    "link_set = set(link_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down to only deadspin.com links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jLCgG5bx4hx"
   },
   "outputs": [],
   "source": [
    "deadspin_links = [l for l in link_set if 'deadspin.com' in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut out any tags and links that don't lead to posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vY64DC0-yDPJ"
   },
   "outputs": [],
   "source": [
    "not_tags = [l for l in deadspin_links if '/c/' not in l and '/tag/' not in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write it out as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yj36ChO6zEG9"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(not_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4Lyh9BLzz3w"
   },
   "outputs": [],
   "source": [
    "df.columns = [\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKzyjbjMz2uW"
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/links.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through the link list and scrape every URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8O7-NUA0CAM"
   },
   "outputs": [],
   "source": [
    "def parse_story(url):\n",
    "    # Skip it if already scraped\n",
    "    if url in cache.keys():\n",
    "      print(f\"Already got {url}\")\n",
    "      return\n",
    "    \n",
    "    # Grab the page\n",
    "    print(f\"Scraping {url}\")\n",
    "    try:\n",
    "      r = requests.get(url)\n",
    "    except Exception:\n",
    "      print(f\"Failed to requesst {url}\")\n",
    "      return\n",
    "    \n",
    "    # Pull out the HTML\n",
    "    html = r.content\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    # Scrape out the data we want\n",
    "    try:\n",
    "        d = {\n",
    "          'url': url,\n",
    "          'headline': soup.find_all(\"h1\")[0].a.text,\n",
    "          'new_vistors': soup.find(\"div\", {\"class\", \"sc-15g8630-0\"})['title'].split()[0],\n",
    "          'visitors': soup.find(\"div\", {\"class\", \"sc-15g8630-0\"}).find_all(\"span\")[1].text,\n",
    "          'pubdate': soup.find(\"a\", {\"class\": \"js_meta-time\"}).text\n",
    "        }\n",
    "    except:\n",
    "        print(f\"Failed to scrape {url}\")\n",
    "        return\n",
    "    # Add it to the cache\n",
    "    cache[url] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SeJmq35U0EXy",
    "outputId": "d83b7851-1eb7-4a7e-fa20-f7c2c0a69f77"
   },
   "outputs": [],
   "source": [
    "result = [parse_story(l) for l in not_tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "wq0W_ygL0JB5",
    "outputId": "3ae16256-3c6a-43c9-9a5e-d54d5835df52"
   },
   "source": [
    "Write out the scraped post data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5ujVbdJ1UOv"
   },
   "outputs": [],
   "source": [
    "scrape_df = pd.DataFrame(cache.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "XW8Ao03kZiIx",
    "outputId": "7cce5984-b48b-4ee3-f25a-d5ad8aab61b9"
   },
   "outputs": [],
   "source": [
    "scrape_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTb6ZXQzZjLb"
   },
   "outputs": [],
   "source": [
    "scrape_df.to_csv('data/posts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Deadspin scrape",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
